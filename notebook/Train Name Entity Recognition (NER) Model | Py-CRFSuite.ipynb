{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Name Entity Recognition (NER) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycrfsuite\n",
    "from itertools import chain\n",
    "import json\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus_text = open(\"../corpus/id_beritagar-ner-train.conllu\", \"r\").read()\n",
    "test_corpus_text = open(\"../corpus/id_beritagar-ner-test.conllu\", \"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus_text = train_corpus_text.split(\"\\n\\n\")\n",
    "test_corpus_text = test_corpus_text.split(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Corpus Train: 2500 \n",
      "Total Corpus Test: 500 \n"
     ]
    }
   ],
   "source": [
    "print(\"Total Corpus Train: %d \" % len(train_corpus_text))\n",
    "print(\"Total Corpus Test: %d \" % len(test_corpus_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = []\n",
    "for corpus in train_corpus_text:\n",
    "    train_corpus.append([line.split(\"\\t\") for line in corpus.split(\"\\n\")[2:]])\n",
    "\n",
    "test_corpus = []\n",
    "for corpus in test_corpus_text:\n",
    "    test_corpus.append([line.split(\"\\t\") for line in corpus.split(\"\\n\")[2:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', 'Celah', 'NN', '_', 'O'],\n",
       " ['2', 'itulah', 'NN', '_', 'O'],\n",
       " ['3', 'yang', 'SC', '_', 'O'],\n",
       " ['4', 'digunakan', 'VB', '_', 'O'],\n",
       " ['5', 'hakim', 'NN', '_', 'O'],\n",
       " ['6', 'MK', 'NNP', '_', 'U-ORG'],\n",
       " ['7', 'untuk', 'SC', '_', 'O'],\n",
       " ['8', 'mempersilakan', 'VB', '_', 'O'],\n",
       " ['9', 'kuasa', 'NN', '_', 'O'],\n",
       " ['10', 'hukum', 'NN', '_', 'O'],\n",
       " ['11', 'paslon', 'NN', '_', 'O'],\n",
       " ['12', '02', 'CD', '_', 'O'],\n",
       " ['13', 'untuk', 'SC', '_', 'O'],\n",
       " ['14', 'membacakan', 'VB', '_', 'O'],\n",
       " ['15', 'permohonan', 'NN', '_', 'O'],\n",
       " ['16', 'yang', 'SC', '_', 'O'],\n",
       " ['17', 'sudah', 'MD', '_', 'O'],\n",
       " ['18', 'dikoreksi', 'VB', '_', 'O'],\n",
       " ['19', '.', 'Z', '_', 'O']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', '\"', 'Z', '_', 'O'],\n",
       " ['2', 'Banyak', 'CD', '_', 'O'],\n",
       " ['3', 'populasi', 'NN', '_', 'O'],\n",
       " ['4', 'dengan', 'IN', '_', 'O'],\n",
       " ['5', 'pertumbuhan', 'NN', '_', 'O'],\n",
       " ['6', 'tercepat', 'JJ', '_', 'O'],\n",
       " ['7', 'terjadi', 'VB', '_', 'O'],\n",
       " ['8', 'di', 'IN', '_', 'O'],\n",
       " ['9', 'negara-negara', 'NN', '_', 'O'],\n",
       " ['10', 'termiskin', 'JJ', '_', 'O'],\n",
       " ['11', 'di', 'IN', '_', 'O'],\n",
       " ['12', 'dunia', 'NN', '_', 'O'],\n",
       " ['13', ',', 'Z', '_', 'O'],\n",
       " ['14', '\"', 'Z', '_', 'O'],\n",
       " ['15', 'kata', 'VB', '_', 'O'],\n",
       " ['16', 'Spoorenberg', 'NNP', '_', 'U-PERSON'],\n",
       " ['17', '.', 'Z', '_', 'O']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    id_, word, postag, head, ner = sent[i]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-4:]=' + word[-4:],\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isalnum=%s' % word.isalnum(),\n",
    "        'word.isalpha=%s' % word.isalpha(),\n",
    "        'word.isdecimal=%s' % word.isdecimal(),\n",
    "        'word.isnumeric=%s' % word.isnumeric(),\n",
    "        'word.isspace=%s' % word.isspace(),\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "    ]\n",
    "    if i > 0:\n",
    "        id_1, word1, postag1, head1, ner1  = sent[i-1]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.isalnum=%s' % word1.isalnum(),\n",
    "            '-1:word.isalpha=%s' % word1.isalpha(),\n",
    "            '-1:word.isdecimal=%s' % word1.isdecimal(),\n",
    "            '-1:word.isnumeric=%s' % word1.isnumeric(),\n",
    "            '-1:word.isspace=%s' % word1.isspace(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isdigit=%s' % word1.isdigit(),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        id_1, word1, postag1, head1, ner1 = sent[i+1]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.isalnum=%s' % word1.isalnum(),\n",
    "            '+1:word.isalpha=%s' % word1.isalpha(),\n",
    "            '+1:word.isdecimal=%s' % word1.isdecimal(),\n",
    "            '+1:word.isnumeric=%s' % word1.isnumeric(),\n",
    "            '+1:word.isspace=%s' % word1.isspace(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isdigit=%s' % word1.isdigit(),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [ner.replace(\"U-\",\"B-\").replace(\"L-\", \"I-\") for id_, word, tag, head, ner in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [word for id_, word, tag, head, ner in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['bias',\n",
       "  'word.lower=celah',\n",
       "  'word[-4:]=elah',\n",
       "  'word[-3:]=lah',\n",
       "  'word[-2:]=ah',\n",
       "  'word.isalnum=True',\n",
       "  'word.isalpha=True',\n",
       "  'word.isdecimal=False',\n",
       "  'word.isnumeric=False',\n",
       "  'word.isspace=False',\n",
       "  'word.isupper=False',\n",
       "  'word.istitle=True',\n",
       "  'word.isdigit=False',\n",
       "  'BOS',\n",
       "  '+1:word.lower=itulah',\n",
       "  '+1:word.isalnum=True',\n",
       "  '+1:word.isalpha=True',\n",
       "  '+1:word.isdecimal=False',\n",
       "  '+1:word.isnumeric=False',\n",
       "  '+1:word.isspace=False',\n",
       "  '+1:word.isupper=False',\n",
       "  '+1:word.istitle=False',\n",
       "  '+1:word.isdigit=False']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(train_corpus[0])[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.17 s, sys: 108 ms, total: 1.28 s\n",
      "Wall time: 1.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = [sent2features(s) for s in train_corpus]\n",
    "y_train = [sent2labels(s) for s in train_corpus]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_corpus]\n",
    "y_test = [sent2labels(s) for s in test_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.06 s, sys: 83.3 ms, total: 2.14 s\n",
      "Wall time: 2.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature.minfreq',\n",
       " 'feature.possible_states',\n",
       " 'feature.possible_transitions',\n",
       " 'c1',\n",
       " 'c2',\n",
       " 'max_iterations',\n",
       " 'num_memories',\n",
       " 'epsilon',\n",
       " 'period',\n",
       " 'delta',\n",
       " 'linesearch',\n",
       " 'max_linesearch']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.4 s, sys: 162 ms, total: 7.56 s\n",
      "Wall time: 7.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train('../model/id_beritagar-ner.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 abdulaziz  staff   316K Jun 25 15:48 ../model/id_beritagar-ner.crfsuite\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ../model/id_beritagar-ner.crfsuite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x128e23f28>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('../model/id_beritagar-ner.crfsuite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Badan Meteorologi , Klimatologi , dan Geofisika ( BMKG ) memprakirakan , seluruh wilayah Sulawesi Barat berawan pagi ini , Senin ( 17 / 06 / 2019 ) . Sementara , berawan diprediksi akan terjadi di sebagian besar wilayah ini pada siang hari .\n",
      "\n",
      "Predicted: B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O B-ORG O O O O O B-GPE I-GPE O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Correct:   B-ORG I-ORG I-ORG I-ORG I-ORG I-ORG I-ORG O B-ORG O O O O O B-GPE I-GPE O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n"
     ]
    }
   ],
   "source": [
    "example_sent = test_corpus[100]\n",
    "print(' '.join(sent2tokens(example_sent)), end='\\n\\n')\n",
    "\n",
    "print(\"Predicted:\", ' '.join(tagger.tag(sent2features(example_sent))))\n",
    "print(\"Correct:  \", ' '.join(sent2labels(example_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Badan Meteorologi , Klimatologi , dan Geofisika', 'ORG'), ('BMKG', 'ORG'), ('Sulawesi Barat', 'GPE')]\n"
     ]
    }
   ],
   "source": [
    "all_ner = []\n",
    "ner = []\n",
    "for i, a in enumerate(tagger.tag(sent2features(example_sent))):\n",
    "    b = example_sent[i]\n",
    "    if a != \"O\":\n",
    "        split_ner = a.split(\"-\")\n",
    "        if split_ner[0] in [\"B\", \"U\"]:\n",
    "            if len(ner)>0:\n",
    "                all_ner.append((\" \".join([z[0] for z in ner]), \" \".join(set([z[1] for z in ner]))))\n",
    "            ner = []\n",
    "            ner.append((b[1],split_ner[1]))\n",
    "        else:\n",
    "            ner.append((b[1],split_ner[1]))\n",
    "all_ner.append((\" \".join([z[0] for z in ner]), \" \".join(set([z[1] for z in ner]))))\n",
    "print(all_ner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bio_classification_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    \n",
    "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
    "    to calculate averages properly!\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "        \n",
    "    tagset = set(lb.classes_) - {'O'}\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 369 ms, sys: 87.6 ms, total: 457 ms\n",
      "Wall time: 662 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = [tagger.tag(xseq) for xseq in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-EVENT       0.88      0.69      0.77        51\n",
      "     I-EVENT       0.80      0.57      0.67        70\n",
      "       B-GPE       0.90      0.87      0.89       359\n",
      "       I-GPE       0.89      0.90      0.90       184\n",
      "      B-MERK       0.94      0.58      0.71        26\n",
      "       B-ORG       0.87      0.85      0.86       507\n",
      "       I-ORG       0.88      0.83      0.86       434\n",
      "    B-PERSON       0.84      0.78      0.81       362\n",
      "    I-PERSON       0.78      0.76      0.77       156\n",
      "   B-PRODUCT       0.71      0.29      0.42        17\n",
      "   I-PRODUCT       0.67      0.08      0.14        26\n",
      "\n",
      "   micro avg       0.87      0.81      0.84      2192\n",
      "   macro avg       0.83      0.66      0.71      2192\n",
      "weighted avg       0.86      0.81      0.83      2192\n",
      " samples avg       0.10      0.10      0.10      2192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bio_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
