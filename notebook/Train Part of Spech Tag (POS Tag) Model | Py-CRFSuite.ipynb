{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Part of Spech Tag (POS Tag) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycrfsuite\n",
    "from itertools import chain\n",
    "import json\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus_text = open(\"../corpus/id_beritagar-ner-train.conllu\", \"r\").read()\n",
    "test_corpus_text = open(\"../corpus/id_beritagar-ner-test.conllu\", \"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus_text = train_corpus_text.split(\"\\n\\n\")\n",
    "test_corpus_text = test_corpus_text.split(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Corpus Train: 2500 \n",
      "Total Corpus Test: 500 \n"
     ]
    }
   ],
   "source": [
    "print(\"Total Corpus Train: %d \" % len(train_corpus_text))\n",
    "print(\"Total Corpus Test: %d \" % len(test_corpus_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = []\n",
    "for corpus in train_corpus_text:\n",
    "    train_corpus.append([line.split(\"\\t\") for line in corpus.split(\"\\n\")[2:]])\n",
    "\n",
    "test_corpus = []\n",
    "for corpus in test_corpus_text:\n",
    "    test_corpus.append([line.split(\"\\t\") for line in corpus.split(\"\\n\")[2:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', 'Celah', 'NN', '_', 'O'],\n",
       " ['2', 'itulah', 'NN', '_', 'O'],\n",
       " ['3', 'yang', 'SC', '_', 'O'],\n",
       " ['4', 'digunakan', 'VB', '_', 'O'],\n",
       " ['5', 'hakim', 'NN', '_', 'O'],\n",
       " ['6', 'MK', 'NNP', '_', 'U-ORG'],\n",
       " ['7', 'untuk', 'SC', '_', 'O'],\n",
       " ['8', 'mempersilakan', 'VB', '_', 'O'],\n",
       " ['9', 'kuasa', 'NN', '_', 'O'],\n",
       " ['10', 'hukum', 'NN', '_', 'O'],\n",
       " ['11', 'paslon', 'NN', '_', 'O'],\n",
       " ['12', '02', 'CD', '_', 'O'],\n",
       " ['13', 'untuk', 'SC', '_', 'O'],\n",
       " ['14', 'membacakan', 'VB', '_', 'O'],\n",
       " ['15', 'permohonan', 'NN', '_', 'O'],\n",
       " ['16', 'yang', 'SC', '_', 'O'],\n",
       " ['17', 'sudah', 'MD', '_', 'O'],\n",
       " ['18', 'dikoreksi', 'VB', '_', 'O'],\n",
       " ['19', '.', 'Z', '_', 'O']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', '\"', 'Z', '_', 'O'],\n",
       " ['2', 'Banyak', 'CD', '_', 'O'],\n",
       " ['3', 'populasi', 'NN', '_', 'O'],\n",
       " ['4', 'dengan', 'IN', '_', 'O'],\n",
       " ['5', 'pertumbuhan', 'NN', '_', 'O'],\n",
       " ['6', 'tercepat', 'JJ', '_', 'O'],\n",
       " ['7', 'terjadi', 'VB', '_', 'O'],\n",
       " ['8', 'di', 'IN', '_', 'O'],\n",
       " ['9', 'negara-negara', 'NN', '_', 'O'],\n",
       " ['10', 'termiskin', 'JJ', '_', 'O'],\n",
       " ['11', 'di', 'IN', '_', 'O'],\n",
       " ['12', 'dunia', 'NN', '_', 'O'],\n",
       " ['13', ',', 'Z', '_', 'O'],\n",
       " ['14', '\"', 'Z', '_', 'O'],\n",
       " ['15', 'kata', 'VB', '_', 'O'],\n",
       " ['16', 'Spoorenberg', 'NNP', '_', 'U-PERSON'],\n",
       " ['17', '.', 'Z', '_', 'O']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    id_, word, postag, head, ner = sent[i]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-4:]=' + word[-4:],\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isalnum=%s' % word.isalnum(),\n",
    "        'word.isalpha=%s' % word.isalpha(),\n",
    "        'word.isdecimal=%s' % word.isdecimal(),\n",
    "        'word.isnumeric=%s' % word.isnumeric(),\n",
    "        'word.isspace=%s' % word.isspace(),\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "    ]\n",
    "    if i > 0:\n",
    "        id_1, word1, postag1, head1, ner1  = sent[i-1]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.isalnum=%s' % word1.isalnum(),\n",
    "            '-1:word.isalpha=%s' % word1.isalpha(),\n",
    "            '-1:word.isdecimal=%s' % word1.isdecimal(),\n",
    "            '-1:word.isnumeric=%s' % word1.isnumeric(),\n",
    "            '-1:word.isspace=%s' % word1.isspace(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isdigit=%s' % word1.isdigit(),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        id_1, word1, postag1, head1, ner1 = sent[i+1]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.isalnum=%s' % word1.isalnum(),\n",
    "            '+1:word.isalpha=%s' % word1.isalpha(),\n",
    "            '+1:word.isdecimal=%s' % word1.isdecimal(),\n",
    "            '+1:word.isnumeric=%s' % word1.isnumeric(),\n",
    "            '+1:word.isspace=%s' % word1.isspace(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isdigit=%s' % word1.isdigit(),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [tag for id_, word, tag, head, ner in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [word for id_, word, tag, head, ner in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['bias',\n",
       "  'word.lower=celah',\n",
       "  'word[-4:]=elah',\n",
       "  'word[-3:]=lah',\n",
       "  'word[-2:]=ah',\n",
       "  'word.isalnum=True',\n",
       "  'word.isalpha=True',\n",
       "  'word.isdecimal=False',\n",
       "  'word.isnumeric=False',\n",
       "  'word.isspace=False',\n",
       "  'word.isupper=False',\n",
       "  'word.istitle=True',\n",
       "  'word.isdigit=False',\n",
       "  'BOS',\n",
       "  '+1:word.lower=itulah',\n",
       "  '+1:word.isalnum=True',\n",
       "  '+1:word.isalpha=True',\n",
       "  '+1:word.isdecimal=False',\n",
       "  '+1:word.isnumeric=False',\n",
       "  '+1:word.isspace=False',\n",
       "  '+1:word.isupper=False',\n",
       "  '+1:word.istitle=False',\n",
       "  '+1:word.isdigit=False']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(train_corpus[0])[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.04 s, sys: 81.4 ms, total: 1.12 s\n",
      "Wall time: 1.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = [sent2features(s) for s in train_corpus]\n",
    "y_train = [sent2labels(s) for s in train_corpus]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_corpus]\n",
    "y_test = [sent2labels(s) for s in test_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.77 s, sys: 35.8 ms, total: 1.81 s\n",
      "Wall time: 1.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature.minfreq',\n",
       " 'feature.possible_states',\n",
       " 'feature.possible_transitions',\n",
       " 'c1',\n",
       " 'c2',\n",
       " 'max_iterations',\n",
       " 'num_memories',\n",
       " 'epsilon',\n",
       " 'period',\n",
       " 'delta',\n",
       " 'linesearch',\n",
       " 'max_linesearch']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.5 s, sys: 64.5 ms, total: 12.6 s\n",
      "Wall time: 12.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train('../model/id_beritagar-postag.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 abdulaziz  staff   418K Jun 25 15:47 ../model/id_beritagar-postag.crfsuite\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ../model/id_beritagar-postag.crfsuite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x121d4a240>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('../model/id_beritagar-postag.crfsuite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Badan Meteorologi , Klimatologi , dan Geofisika ( BMKG ) memprakirakan , seluruh wilayah Sulawesi Barat berawan pagi ini , Senin ( 17 / 06 / 2019 ) . Sementara , berawan diprediksi akan terjadi di sebagian besar wilayah ini pada siang hari .\n",
      "\n",
      "Predicted: NNP NNP Z NNP Z CC NNP Z NNP Z VB Z CD NN NNP NNP VB NN PR Z NNP Z CD Z CD Z CD Z Z SC Z NN NN MD VB IN NN JJ NN PR IN NN NN Z\n",
      "Correct:   NNP NNP Z NNP Z CC NNP Z NNP Z VB Z CD NN NNP NNP VB NN PR Z NNP Z CD Z CD Z CD Z Z SC Z NN NN MD VB IN NN JJ NN PR IN NN NN Z\n"
     ]
    }
   ],
   "source": [
    "example_sent = test_corpus[100]\n",
    "print(' '.join(sent2tokens(example_sent)), end='\\n\\n')\n",
    "\n",
    "print(\"Predicted:\", ' '.join(tagger.tag(sent2features(example_sent))))\n",
    "print(\"Correct:  \", ' '.join(sent2labels(example_sent)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postag_classification_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    \n",
    "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
    "    to calculate averages properly!\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "        \n",
    "    tagset = set(lb.classes_) - {'O'}\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 334 ms, sys: 11.6 ms, total: 345 ms\n",
      "Wall time: 346 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = [tagger.tag(xseq) for xseq in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.99      0.99      0.99       477\n",
      "          CD       0.98      0.98      0.98      1044\n",
      "          DT       1.00      1.00      1.00        25\n",
      "          FW       0.95      0.62      0.75        65\n",
      "          IN       0.99      0.99      0.99      1273\n",
      "          JJ       0.95      0.90      0.92       498\n",
      "          MD       0.99      0.99      0.99       315\n",
      "         NEG       0.98      0.97      0.98       122\n",
      "          NN       0.95      0.97      0.96      3861\n",
      "         NND       0.95      0.90      0.93        42\n",
      "         NNP       0.98      0.98      0.98      2763\n",
      "          OD       0.93      0.88      0.90        32\n",
      "          PR       1.00      1.00      1.00       380\n",
      "         PRP       0.99      0.98      0.98       125\n",
      "          RB       0.96      0.96      0.96       490\n",
      "          RP       0.96      0.96      0.96        23\n",
      "          SC       0.99      0.97      0.98       585\n",
      "         SYM       1.00      0.95      0.97        20\n",
      "          VB       0.95      0.94      0.94      1736\n",
      "          WH       0.86      0.90      0.88        42\n",
      "           X       0.50      1.00      0.67         1\n",
      "           Z       1.00      1.00      1.00      3043\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     16962\n",
      "   macro avg       0.95      0.95      0.94     16962\n",
      "weighted avg       0.97      0.97      0.97     16962\n",
      " samples avg       0.97      0.97      0.97     16962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(postag_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
